I"8<h1 id="tao_of_parallism">tao_of_parallism</h1>

<p class="meta">18 May 2022 - Wuhan</p>

<h1 id="摘要">摘要</h1>

<p>常规的并行算法对于关键数据结构是非常规数据结构例如图，树，集合，依赖图不是一个合适的抽象。提炼出对并行化很重要的算法属性，从数据并行中概括出的无固定形状的数据并行无处不在，依赖于算法的tao结构，并行化可能在于编译时间，解析器执行器或者优化器并行，因此统一化称为不相关的并行化技术。</p>

<h1 id="背景">背景</h1>

<ul>
  <li>形状分析不行</li>
  <li>静态依赖图不行，</li>
</ul>

<h1 id="算法的算子公式化">算法的算子公式化</h1>

<ul>
  <li>
    <p>激活元素</p>
  </li>
  <li>
    <p>邻居</p>
  </li>
  <li>
    <p>顺序</p>
  </li>
</ul>

<h2 id="galois-set-iterators">Galois set iterators</h2>

<p><code class="language-plaintext highlighter-rouge">Unordered-set iterator: foreach (e in Set S) {B(e)}</code></p>

<p>选择的顺序是不确定的</p>

<h1 id="三个维度-topology-activte-node-operator">三个维度 topology, activte node, operator</h1>

<h2 id="topology">topology</h2>

<p>描述了承载计算的数据结构</p>

<p>高度结构化拓扑结构可以用一小部分参数描述，而非结构化的拓扑需要冗长的描述。<strong>图的拓扑结构</strong>是算法实现可用优化类型的重要指标； 例如，图具有高度结构化拓扑的算法可能适合静态分析和优化。</p>

<h3 id="结构化">结构化</h3>

<p>同构集合和多重集合——包含nodes但是no edges的图</p>

<h3 id="半结构化">半结构化</h3>

<p>树——有结构化的不变量，但是很多树的节点和边都一样</p>

<h3 id="无结构化">无结构化</h3>

<p>一般的图</p>

<h2 id="激活节点">激活节点</h2>

<p>描述节点怎么激活和他们必须处理的顺序</p>

<ol>
  <li>
    <p>位置：拓扑驱动和数据驱动的方式。</p>

    <p>​	拓扑驱动算法：激活节点由图决定，因此，<strong>在某个活动节点上执行运算符不会导致其他节点变为活动状态</strong>。常见的例子是迭代图的所有节点或边的算法。</p>

    <p>​	数据驱动算法：一个节点上的活动可能会导致其他节点变得活跃，因此节点<strong>以数据相关且不可预测的方式变得活跃</strong>。 一些示例是用于图形中最大流计算的 preflow-push 算法和用于事件驱动模拟的算法。</p>
  </li>
  <li>
    <p>顺序：激活节点在算法中有序但是其他无序</p>
  </li>
</ol>

<h2 id="operator">operator</h2>

<h3 id="morph">morph</h3>

<p>变形算子可以通过添加或删除节点和边来修改其邻域，也可以更新节点和边上的值。</p>

<h3 id="局部计算">局部计算</h3>

<p>局部操作在领域中更新存在节点和边中的值，但是它不改变图的连通性。</p>

<h3 id="reader">reader</h3>

<p>如果运算符不以任何方式修改数据结构，则它是数据结构的读取器。</p>

<h1 id="无定形的数据并行">无定形的数据并行</h1>

<p>当活动节点是<strong>无序</strong>的时，邻域约束必须确保<strong>并行执行活动产生的输出与按某种顺序一次执行一个活动产生的输出相同</strong>。对于已排序的活动元素，此顺序必须与活动元素上的顺序相同。</p>

<ul>
  <li>给定一组活动节点和活动节点的排序，无定形数据并行性是指<strong>同时处理活动节点时产生的并行性</strong>，这种并行性受到<strong>邻域和排序约束</strong>。
    <ul>
      <li>并发操作可能会相互冲突</li>
      <li>活动可以动态创建</li>
      <li>活动可能会修改底层数据结构</li>
    </ul>
  </li>
</ul>

<h2 id="baseline推测的并行执行">baseline：推测的并行执行</h2>

<p>图存储在<strong>共享内存</strong>中，活动节点由<strong>一定数量的线程处理</strong>。线程从工作集中选择一个活动节点，并推测将操作符应用于该节点，根据需要调用图API执行对图的操作。</p>

<p>相邻区域不相交，并发图类可以使用<strong>排它逻辑锁</strong>：每个图元素都有一个排他锁，线程必须先获得锁然后再访问元素。<strong>锁一直保持到活动终止</strong>。如果由于锁已经由另一个线程拥有而无法获得锁，则会向运行时系统报告一个冲突，从而<strong>回滚</strong>一个冲突的活动.</p>

<p>锁操作完全由图类中的方法执行;此外，为了支持回滚，每个修改图的图API方法在修改前都要复制数据，就像其他使用事务内存和线程级投机的系统一样</p>

<ul>
  <li>如果活动元素没有排序，则该活动在操作符的应用程序完成时提交，然后释放所有获得的锁</li>
  <li>如果活动元素是有序的，那么活动节点仍然可以以任何顺序处理，但是它们必须以串行顺序提交</li>
  <li>如果这些活动不修改这些活动的交点上的节点和边，那么并发活动的邻域可以被允许重叠。因此，如果我们识别只读数据结构并且不锁定它们的元素，额外的并发是可能的;读写器锁是另一种解决方案。最一般的解是使用交换性条件;这允许并行执行迭代，即使它们对共享变量执行缩减操作</li>
</ul>

<h2 id="并行配置">并行配置</h2>

<p>不规则算法中无定形并行度的一个衡量标准是，对于给定的输入，在算法的每一步中，可以并行处理的活动节点的数量，假设</p>

<ul>
  <li>
    <p>有一个无限大的处理器数量</p>
  </li>
  <li>一个活动需要一个时间步骤来执行</li>
  <li>系统对邻域约束和排序约束有完善的知识，因此它只执行能够成功完成的活动，</li>
  <li>每一步都执行一个最大的非冲突活动集合</li>
</ul>

<h2 id="探索数据结构减少开销">探索数据结构减少开销</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>如果运算符的实现在修改邻域的任何元素之前读取其所有元素——谨慎的
A. 按顺序读a，写a，读b，写b
B. 读a，读b，写a，写b
</code></pre></div></div>

<p><strong>写全读后写的无序算法可以随机的执行，无需缓存更新或者对修改后的数据进行备份</strong>，因为所有冲突都是在操作符执行的只读阶段检测到的</p>

<h2 id="探索结构的协调调度">探索结构的协调调度</h2>

<p>在基线系统中实现的调度策略可以称为<strong>自治调度</strong>，因为活动以不协调的方式执行，需要在线冲突<strong>检测和回滚</strong>才能正确执行。</p>

<p>如果我们确保只安排非冲突的迭代同时执行(我们称之为<strong>协调调度的策略</strong>)，那么投机性的开销就被消除了</p>

<p>所有这些策略都是基于显式或隐式地构造依赖图，但是它们是在程序编译和执行期间的不同时刻进行构造的。</p>

<p><img src="C:\Users\lyj\AppData\Roaming\Typora\typora-user-images\image-20220516115430059.png" alt="image-20220516115430059" /></p>

<p>在算子公式方面，依赖图的构建包括以下步骤:</p>

<p>(i)确定所有<strong>活动节点</strong>;</p>

<p>(ii)确定<strong>对应活动的邻域和排序</strong>;</p>

<p>(iii)创建尊重<strong>邻域约束和排序约束</strong>的活动的部分顺序</p>

<p>然后，活动可以并行执行，无需猜测，但需要适当的同步，以确保活动的部分顺序得到遵守。</p>

<blockquote>
  <p>虽然这种方法看起来很明显，但是像<strong>事件驱动模拟</strong>这样<strong>有序的数据驱动算法</strong>通常不能使用这种方法并行化:一个活动的执行可能会导致一个新节点变为活动，并且这个新活动可能比现有活动具有更高的优先级，并与现有活动发生冲突。</p>
</blockquote>

<h2 id="运行时协调">运行时协调</h2>

<blockquote>
  <p>运行时协调可以用于除有序的数据驱动算法之外的所有不规则算法</p>
</blockquote>

<h3 id="无序数据驱动算法">无序数据驱动算法</h3>

<p>通过将<strong>依赖图</strong>的构造与活动的执行交织在一起，这些算法可以在无需推测的情况下并行化。算法的执行是<strong>逐轮</strong>进行的。</p>

<p>在每一轮中，选择一组<strong>不冲突的活动</strong>并并行执行，<strong>不需要同步</strong></p>

<p>任何新创建的活动将被推迟到下一轮，届时它们将与当前一轮中未处理的活动一起被考虑执行。</p>

<p>实施这一策略需要解决两个问题:</p>

<p>(i)我们如何<strong>计算活动的邻域</strong>，以及</p>

<p>(ii)给定一组活动及其邻域，我们<strong>如何找到一组非冲突的活动</strong>?</p>

<p>一般情况下，完全执行操作符的邻域，这可能会对全局数据结构产生副作用。如果某个活动在当前轮中没有被选择执行(因为冲突)，则必须撤销这些副作用，以便正确执行。一个解决方案是将<strong>这些更新私有化</strong>，就像在事务内存的某些版本中所做的那样。实际上，活动在每一轮中执行两次:一次是私有化，以确定社区，然后如果他们在当前一轮中被选择执行，那么再一次是真正的。从字面上看，这种策略并不是很有效;</p>

<p>在变形算法中，大多数操作符的实现都是<strong>谨慎的</strong>（先读后写），所以<strong>活动的邻域可以通过部分执行来确定，直到活动开始对邻域进行修改</strong>。如果活动在该轮中被选择执行，则执行只是从该点继续。</p>

<p>一旦确定了所有活动的邻域，我们就可以构建一个冲突图，其中节点代表算法中的活动节点，而边代表活动之间的冲突。可以使用ruby的随机并行算法找到一个最大的独立活动集[43]，这组活动可以在不同步的情况下并行执行。可以将此方法视为逐层构建和利用依赖图，并在级别之间使用障碍同步</p>

<h3 id="拓扑驱动算法">拓扑驱动算法</h3>

<p>活动不会创建新的活动节点，因此无序和有序算法都可以使用运行时协调来执行。</p>

<p>无序拓扑驱动的算法可以像上面描述的那样逐轮执行。这种方法的一种变体可以用于<strong>有序拓扑驱动算法</strong>。在这种情况下，我们找到<strong>活动节点序列的最大前缀(</strong>而不是活动节点集合的最大独立集合)，使前缀中的<strong>所有活动节点都具有互不干扰的邻域</strong>，并并行执行这些节点。然后可以使用剩余的活动节点后缀重复此过程。</p>

<h2 id="及时协调">及时协调</h2>

<p>对于一些拓扑驱动的算法，依赖图不依赖于图的节点和边上的标签，纯粹是图拓扑的函数。因此，依赖图可以在<strong>输入图给出之后、程序执行之前的运行时生成</strong>。我们称这种策略为just-in-time coordination</p>

<p>对于易于<strong>即时调度的拓扑驱动变形算法</strong>，由于在算法执行过程中可以修改图的结构，改变邻域和依赖关系，因此对图的检查可能不够</p>

<h2 id="编译时协调">编译时协调</h2>

<p>些适合即时协调的算法具有结构化的输入图。在这种情况下，可以在编译时生成由<strong>输入图的未知参数适当参数化</strong>的依赖图</p>

<p>如果算法是<strong>拓扑驱动的本地计算</strong>，并且活动的邻域只是活动节点本身，忽略只读数据结构，那么<strong>编译时协调</strong>也可以不受拓扑的影响。在这种情况下，<strong>活动是基本独立的</strong>(受顺序约束)，因为每个活动都修改图的一个不相交的部分。一个典型的例子是计算图中每个节点的结果。输出是一个按节点索引的向量。每个活动读取图形的一部分，但只写入输出向量中特定于节点的部分。</p>

<h1 id="算法的案例学习">算法的案例学习</h1>

<h2 id="变体算法">变体算法</h2>

<p>细化:细化操作通过添加<strong>新的节点和边</strong>使图变大，在这个过程中可能会删除一些节点和边。</p>

<p>粗化:粗化运算符将<strong>节点或子图</strong>聚集在一起，用代表集群的更小的子图替换它们</p>

<p>一般变形:所有<strong>其他修改图形结构</strong>的操作都属于这一类。</p>

<h3 id="细化">细化</h3>

<p>数据驱动的优化算法通常在单个图上运行。大多数拓扑驱动的细化操作符操作两个数据结构Gi和Go;<strong>Gi是只读的</strong>，它的拓扑结构决定了算法中的活动节点，而<strong>Go则根据每个活动而变化</strong></p>

<p>map-reduce:在map-reduce编程模型[13]中，<strong>map操作对集合或多集合Si的每个元素“逐点”应用一个函数</strong>，以生成另一个集合或多集合<strong>So</strong>。活动节点是Si的元素，它们可以以任何顺序进行处理。这是一个拓扑驱动的无序算法，是So的细化变体，因为元素是在执行期间递增地添加到So的。</p>

<p>流:像StreamIt[21]这样的语言中的流操作符是从输入流到输出流的细化变体(流是非严格序列[53])。无状态和有状态流操作符可以用序列上的无序和有序迭代表示</p>

<p>Prim的MST算法:大多数以自顶向下的方式构建树的算法使用细化变体。</p>

<h3 id="粗化">粗化</h3>

<p>边收缩、节点消除和子图收缩。</p>

<h2 id="局部计算算法">局部计算算法</h2>

<h3 id="拓扑驱动的局部计算算法">拓扑驱动的局部计算算法</h3>

<p><strong>活动节点和邻居都可以从网络结构中确定</strong>，这在编译时就知道了，编译时调度可以有效的协调计算。大多数Jacobi迭代的并行实现都将网格划分为块，每个处理器负责更新一个块中的节点。这种数据分布比其他分布(如行或列循环分布)需要更少的处理器间通信。</p>

<h3 id="数据驱动的局部计算算法">数据驱动的局部计算算法</h3>

<p>有一组<strong>初始活动节点，执行一项活动可能导致其他节点也活动</strong>，因此节点以一种不可预测的、数据驱动的方式活动。</p>
:ET